Experiment 3: Modified ``d_hid``
--------------------------------

Tokenizers
~~~~~~~~~~

Tokenizers' experiment shared by models.

+------------+------------+----------+-----------+-----------+-------+------------+
| tknzr_name | dset_name  | exp_name | max_vocab | min_count | ver   | is_uncased |
+============+============+==========+===========+===========+=======+============+
| whitespace | wikitext-2 | ws-tknzr | -1        | 10        | train | True       |
+------------+------------+----------+-----------+-----------+-------+------------+

Models Shared Parameters
~~~~~~~~~~~~~~~~~~~~~~~~

+----------------+------------+
| parameters     | value      |
+================+============+
| batch_size     | 32         |
+----------------+------------+
| beta1          | 0.9        |
+----------------+------------+
| beta2          | 0.99       |
+----------------+------------+
| ckpt_step      | 5000       |
+----------------+------------+
| dset_name      | wikitext-2 |
+----------------+------------+
| eps            | 1e-8       |
+----------------+------------+
| log_step       | 2500       |
+----------------+------------+
| lr             | 1e-3       |
+----------------+------------+
| max_norm       | 1          |
+----------------+------------+
| max_seq_len    | 512        |
+----------------+------------+
| n_epoch        | 200        |
+----------------+------------+
| seed           | 42         |
+----------------+------------+
| tknzr_exp_name | ws-tknzr   |
+----------------+------------+
| ver            | train      |
+----------------+------------+
| d_emb          | 100        |
+----------------+------------+
| n_hid_lyr      | 2          |
+----------------+------------+
| n_post_hid_lyr | 2          |
+----------------+------------+
| n_pre_hid_lyr  | 2          |
+----------------+------------+
| p_emb          | 0.1        |
+----------------+------------+
| p_hid          | 0.1        |
+----------------+------------+
| wd             | 1e-2       |
+----------------+------------+


Models Perplexity Performance
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

+----------------------------------------------------------------------+
| Training Set                                                         |
+-----------+-----------+-----------+----------+-----------+-----------+
| ``d_hid`` | step 10k  | step 30k  | step 50k | step 70k  | step 90k  |
+===========+===========+===========+==========+===========+===========+
| 128       | 4.293     | 3.741     | 3.562    | 3.451     | 3.358     |
+-----------+-----------+-----------+----------+-----------+-----------+
| 256       | 3.82      | 3.25      | 3.057    | 2.941     | 2.855     |
+-----------+-----------+-----------+----------+-----------+-----------+
| 384       | 3.553     | 2.935     | 2.715    | 2.591     | 2.5       |
+-----------+-----------+-----------+----------+-----------+-----------+
| 512       | 3.322     | 2.63      | 2.382    | 2.253     | 2.151     |
+-----------+-----------+-----------+----------+-----------+-----------+
| 640       | 3.121     | 2.359     | 2.08     | 1.942     | 1.845     |
+-----------+-----------+-----------+----------+-----------+-----------+
| 768       | 2.995     | 2.151     | 1.862    | 1.713     | 1.626     |
+-----------+-----------+-----------+----------+-----------+-----------+
| 896       | **2.792** | **1.907** | **1.62** | **1.485** | **1.414** |
+-----------+-----------+-----------+----------+-----------+-----------+

+-----------------------------------------------------------------------+
| Validation Set                                                        |
+-----------+-----------+-----------+-----------+-----------+-----------+
| ``d_hid`` | step 10k  | step 30k  | step 50k  | step 70k  | step 90k  |
+===========+===========+===========+===========+===========+===========+
| 128       | 4.045     | 3.704     | 3.62      | 3.575     | 3.544     |
+-----------+-----------+-----------+-----------+-----------+-----------+
| 256       | 3.78      | **3.522** | **3.472** | **3.455** | **3.444** |
+-----------+-----------+-----------+-----------+-----------+-----------+
| 384       | 3.711     | 3.53      | 3.556     | 3.558     | 3.559     |
+-----------+-----------+-----------+-----------+-----------+-----------+
| 512       | **3.697** | 3.659     | 3.774     | 3.808     | 3.846     |
+-----------+-----------+-----------+-----------+-----------+-----------+
| 640       | 3.737     | 3.848     | 4.112     | 4.192     | 4.282     |
+-----------+-----------+-----------+-----------+-----------+-----------+
| 768       | 3.772     | 4.068     | 4.476     | 4.705     | 4.806     |
+-----------+-----------+-----------+-----------+-----------+-----------+
| 896       | 3.877     | 4.475     | 5.167     | 5.513     | 5.641     |
+-----------+-----------+-----------+-----------+-----------+-----------+

+------------------------------------------------------------------------+
| Testing Set                                                            |
+-----------+-----------+-----------+------------+-----------+-----------+
| ``d_hid`` | step 10k  | step 30k  | step 50k   | step 70k  | step 90k  |
+===========+===========+===========+============+===========+===========+
| 128       | 4.028     | 3.709     | 3.617      | 3.57      | 3.533     |
+-----------+-----------+-----------+------------+-----------+-----------+
| 256       | 3.762     | **3.515** | **3.472**  | **3.458** | **3.448** |
+-----------+-----------+-----------+------------+-----------+-----------+
| 384       | 3.703     | 3.532     | 3.557      | 3.562     | 3.565     |
+-----------+-----------+-----------+------------+-----------+-----------+
| 512       | **3.686** | 3.657     | 3.783      | 3.826     | 3.885     |
+-----------+-----------+-----------+------------+-----------+-----------+
| 640       | 3.724     | 3.863     | 4.159      | 4.256     | 4.332     |
+-----------+-----------+-----------+------------+-----------+-----------+
| 768       | 3.76      | 4.124     | 4.584      | 4.851     | 4.929     |
+-----------+-----------+-----------+------------+-----------+-----------+
| 896       | 3.883     | 4.551     | 5.326      | 5.728     | 5.886     |
+-----------+-----------+-----------+------------+-----------+-----------+


Conclusions
~~~~~~~~~~~

- Perplexity performance on **training set**:
    - ``d_hid=896`` perform the **best** on all steps.
    - ``d_hid=128`` perform the **worst** on all steps.
- Perplexity performance on **validation set**:
    - ``d_hid=256`` perform the **best** on ``30k`` and ``50k`` and ``70k`` and ``90k`` steps.
    - ``d_hid=128`` perform the **worst** on ``10k`` steps.
    - ``d_hid=896`` perform the **worst** on ``30k`` and ``50k`` and ``70k`` and ``90k`` steps.
- Perplexity performance on **testing set**:
    - ``d_hid=256`` perform the **best** on ``30k`` and ``50k`` and ``70k`` and ``90k`` steps.
    - ``d_hid=128`` perform the **worst** on ``10k`` steps.
    - ``d_hid=896`` perform the **worst** on ``30k`` and ``50k`` and ``70k`` and ``90k`` steps.
- ``d_hid=896`` is **overfitting**.
    - ``d_hid=896`` perform **best** on **training set**, but perform poor on **validation set** and **testing set**.
- ``d_hid=128`` is **underfitting**.
    - ``d_hid=128`` perform the **worst** on all sets.
- ``d_hid=256`` perform the **best** on **validation set** and **testing set**.
