WikiText-2 Dataset
==================

Experiment 1: Models Performance Baseline
-----------------------------------------

Tokenizers
~~~~~~~~~~

Tokenizers' experiment shared by models.

+------------+------------+----------+-----------+-----------+-------+------------+
| tknzr_name | dset_name  | exp_name | max_vocab | min_count | ver   | is_uncased |
+============+============+==========+===========+===========+=======+============+
| whitespace | wikitext-2 | ws-tknzr | -1        | 10        | train | True       |
+------------+------------+----------+-----------+-----------+-------+------------+

Models Shared Parameters
~~~~~~~~~~~~~~~~~~~~~~~~

+----------------+------------+
| parameters     | value      |
+================+============+
| batch_size     | 32         |
+----------------+------------+
| beta1          | 0.9        |
+----------------+------------+
| beta2          | 0.99       |
+----------------+------------+
| ckpt_step      | 2500       |
+----------------+------------+
| dset_name      | wikitext-2 |
+----------------+------------+
| eps            | 1e-8       |
+----------------+------------+
| log_step       | 1000       |
+----------------+------------+
| lr             | 1e-3       |
+----------------+------------+
| max_norm       | 1          |
+----------------+------------+
| max_seq_len    | 256        |
+----------------+------------+
| n_epoch        | 100        |
+----------------+------------+
| seed           | 42         |
+----------------+------------+
| tknzr_exp_name | ws-tknzr   |
+----------------+------------+
| ver            | train      |
+----------------+------------+
| d_emb          | 100        |
+----------------+------------+
| d_hid          | 300        |
+----------------+------------+
| n_hid_lyr      | 2          |
+----------------+------------+
| n_post_hid_lyr | 2          |
+----------------+------------+
| n_pre_hid_lyr  | 2          |
+----------------+------------+
| p_emb          | 0.1        |
+----------------+------------+
| p_hid          | 0.1        |
+----------------+------------+
| wd             | 1e-2       |
+----------------+------------+

Models Loss Performance
~~~~~~~~~~~~~~~~~~~~~~~

+----------------+-----------+----------+----------+-----------+
| model_name     | step 10k  | step 20k | step 50k | step 54k  |
+================+===========+==========+==========+===========+
| RNN            | 2.228     | 2.153    | 2.114    | 2.106     |
+----------------+-----------+----------+----------+-----------+
| GRU            | 2.110     | 1.995    | 1.89     | 1.878     |
+----------------+-----------+----------+----------+-----------+
| LSTM           | **2.085** | **1.96** | **1.84** | **1.822** |
+----------------+-----------+----------+----------+-----------+
| res-RNN        | 2.24      | 2.148    | 2.12     | 2.111     |
+----------------+-----------+----------+----------+-----------+
| res-GRU        | 2.108     | 2.008    | 1.893    | 1.879     |
+----------------+-----------+----------+----------+-----------+
| res-LSTM       | 2.11      | 1.985    | 1.866    | 1.853     |
+----------------+-----------+----------+----------+-----------+
| sattn-RNN      | 2.91      | 2.902    | 2.911    | 2.909     |
+----------------+-----------+----------+----------+-----------+
| sattn-GRU      | 2.901     | 2.906    | 2.908    | 2.911     |
+----------------+-----------+----------+----------+-----------+
| sattn-LSTM     | 2.907     | 2.902    | 2.909    | 2.899     |
+----------------+-----------+----------+----------+-----------+
| res-sattn-RNN  | 2.201     | 2.092    | 1.998    | 1.983     |
+----------------+-----------+----------+----------+-----------+
| res-sattn-GRU  | 2.15      | 2.024    | 1.9      | 1.886     |
+----------------+-----------+----------+----------+-----------+
| res-sattn-LSTM | 2.126     | 1.983    | 1.843    | 1.829     |
+----------------+-----------+----------+----------+-----------+

Models Perplexity Performance
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

+----------------------------------------------------------------+
| Training Set                                                   |
+----------------+----------+-----------+-----------+------------+
| model_name     | step 10k | step 20k  | step 50k  | step 52.5k |
+================+==========+===========+===========+============+
| RNN            | 22.63    | 19.62     | 18.38     | 18.47      |
+----------------+----------+-----------+-----------+------------+
| GRU            | 17.68    | 14.2      | 11.21     | 11.11      |
+----------------+----------+-----------+-----------+------------+
| LSTM           | **17**   | **13.31** | 10.16     | 10.11      |
+----------------+----------+-----------+-----------+------------+
| res-RNN        | 22.65    | 19.55     | 18.16     | 18.04      |
+----------------+----------+-----------+-----------+------------+
| res-GRU        | 17.82    | 14.23     | 11.23     | 11.09      |
+----------------+----------+-----------+-----------+------------+
| res-LSTM       | 17.59    | 13.83     | 10.68     | 10.57      |
+----------------+----------+-----------+-----------+------------+
| sattn-RNN      | 88.77    | 88.69     | 88.56     | 88.6       |
+----------------+----------+-----------+-----------+------------+
| sattn-GRU      | 88.71    | 88.71     | 88.55     | 88.57      |
+----------------+----------+-----------+-----------+------------+
| sattn-LSTM     | 88.81    | 88.62     | 88.56     | 88.67      |
+----------------+----------+-----------+-----------+------------+
| res-sattn-RNN  | 21.21    | 17.22     | 14.06     | 13.96      |
+----------------+----------+-----------+-----------+------------+
| res-sattn-GRU  | 18.87    | 15.01     | 11.73     | 11.58      |
+----------------+----------+-----------+-----------+------------+
| res-sattn-LSTM | 18.25    | 13.93     | **10.11** | **9.993**  |
+----------------+----------+-----------+-----------+------------+

+----------------------------------------------------------------+
| Validation Set                                                 |
+----------------+-----------+----------+-----------+------------+
| model_name     | step 10k  | step 20k | step 50k  | step 52.5k |
+================+===========+==========+===========+============+
| RNN            | 22.82     | 20.59    | 19.89     | 20.01      |
+----------------+-----------+----------+-----------+------------+
| GRU            | 19.55     | 17.7     | 16.48     | 16.39      |
+----------------+-----------+----------+-----------+------------+
| LSTM           | **19.07** | **17.1** | **16.26** | **16.23**  |
+----------------+-----------+----------+-----------+------------+
| res-RNN        | 22.98     | 20.58    | 19.94     | 19.85      |
+----------------+-----------+----------+-----------+------------+
| res-GRU        | 19.62     | 17.55    | 16.67     | 16.47      |
+----------------+-----------+----------+-----------+------------+
| res-LSTM       | 19.44     | 17.4     | 16.71     | 16.67      |
+----------------+-----------+----------+-----------+------------+
| sattn-RNN      | 75.31     | 75.09    | 75        | 75.14      |
+----------------+-----------+----------+-----------+------------+
| sattn-GRU      | 75.23     | 75.11    | 75.08     | 75.15      |
+----------------+-----------+----------+-----------+------------+
| sattn-LSTM     | 75.24     | 75.07    | 75.04     | 75.09      |
+----------------+-----------+----------+-----------+------------+
| res-sattn-RNN  | 21.74     | 18.94    | 17.13     | 17.18      |
+----------------+-----------+----------+-----------+------------+
| res-sattn-GRU  | 20.38     | 18.08    | 17.21     | 16.93      |
+----------------+-----------+----------+-----------+------------+
| res-sattn-LSTM | 20.02     | 17.92    | 17.82     | 17.65      |
+----------------+-----------+----------+-----------+------------+

+---------------------------------------------------------------+
| Testing Set                                                   |
+----------------+-----------+----------+----------+------------+
| model_name     | step 10k  | step 20k | step 50k | step 52.5k |
+================+===========+==========+==========+============+
| RNN            | 21        | 19.03    | 18.66    | 18.52      |
+----------------+-----------+----------+----------+------------+
| GRU            | 18.09     | 16.63    | 15.52    | 15.5       |
+----------------+-----------+----------+----------+------------+
| LSTM           | **17.54** | **16**   | **15.4** | **15.34**  |
+----------------+-----------+----------+----------+------------+
| res-RNN        | 20.98     | 19.03    | 18.53    | 18.57      |
+----------------+-----------+----------+----------+------------+
| res-GRU        | 18.14     | 16.45    | 15.67    | 15.54      |
+----------------+-----------+----------+----------+------------+
| res-LSTM       | 17.93     | 16.22    | 15.77    | 15.8       |
+----------------+-----------+----------+----------+------------+
| sattn-RNN      | 72.03     | 71.85    | 71.8     | 71.97      |
+----------------+-----------+----------+----------+------------+
| sattn-GRU      | 71.9      | 71.92    | 71.92    | 71.9       |
+----------------+-----------+----------+----------+------------+
| sattn-LSTM     | 72.01     | 71.86    | 71.86    | 71.87      |
+----------------+-----------+----------+----------+------------+
| res-sattn-RNN  | 19.99     | 17.6     | 16.08    | 16.15      |
+----------------+-----------+----------+----------+------------+
| res-sattn-GRU  | 18.86     | 16.9     | 16.17    | 15.8       |
+----------------+-----------+----------+----------+------------+
| res-sattn-LSTM | 18.39     | 16.72    | 16.62    | 16.6       |
+----------------+-----------+----------+----------+------------+

Conclusions
~~~~~~~~~~~

- ``sattn`` models seems to have some bugs, we will not discuss the results on them.
- Loss performance on **training set**:
    - **LSTM** perform the best on all steps.
    - **RNN** perform the worst on all steps.
- Perplexity performance on **training set**:
    - **LSTM** perform the best on ``10k`` and ``20k`` steps.
    - **res-sattn-LSTM** perform the best on ``50k`` and ``52.5k`` steps.
    - **RNN** perform the worst on all steps.
- Perplexity performance on **validation set**:
    - **LSTM** perform the best on all steps.
    - **RNN** perform the worst on all steps.
- Perplexity performance on **testing set**:
    - **LSTM** perform the best on all steps.
    - **RNN** perform the worst on all steps.
- Loss does not **directly** reflect on perplexity.
    - **LSTM** got the best loss but **GRU** got the best perplexity
- Using residual connections does help on **RNN**, but not on **GRU** and even worse on **LSTM**.
- Loss does not go down much after ``50k`` steps.
